{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c64ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting Boruta\n",
      "  Downloading Boruta-0.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\program files\\python311\\lib\\site-packages (from Boruta) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\program files\\python311\\lib\\site-packages (from Boruta) (1.6.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\program files\\python311\\lib\\site-packages (from Boruta) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn>=0.17.1->Boruta) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn>=0.17.1->Boruta) (3.5.0)\n",
      "Downloading Boruta-0.4.3-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: Boruta\n",
      "Successfully installed Boruta-0.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56168e",
   "metadata": {},
   "source": [
    "$$\\text{Dữ liệu Gốc} \\rightarrow \\text{EDA} \\rightarrow \\text{Xử lý Giá trị Thiếu/Encoding} \n",
    "\n",
    "\\rightarrow \\text{TRAIN-TEST SPLIT} \\rightarrow \\text{Scaling/PCA} \\rightarrow \\text{Training}\n",
    "\n",
    " \\rightarrow \\text{Evaluation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde51e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# instantiate random forest\n",
    "forest = RandomForestRegressor(n_jobs = -1, max_depth = 5)\n",
    "\n",
    "# fit boruta\n",
    "boruta_selector = BorutaPy(forest, n_estimators = 'auto', random_state = 0)\n",
    "boruta_selector.fit(np.array(X_trn), np.array(y_trn))\n",
    "\n",
    "# store results\n",
    "boruta_ranking = boruta_selector.ranking_\n",
    "selected_features = np.array(feature_names)[boruta_ranking <= 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efd1b1",
   "metadata": {},
   "source": [
    "# Unsupervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7c6f45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     15\u001b[0m data_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 5 Cột số (Num): A và D tương quan cao, E phương sai thấp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum_A\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(data_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum_B\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m10\u001b[39m, data_size),\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum_C\u001b[39m\u001b[38;5;124m'\u001b[39m: (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(data_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m) \u001b[38;5;241m+\u001b[39m (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(data_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m), \n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum_D\u001b[39m\u001b[38;5;124m'\u001b[39m: (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(data_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m) \u001b[38;5;241m+\u001b[39m (\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum_A\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.95\u001b[39m), \u001b[38;5;66;03m# Tương quan rất cao với Num_A\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum_E\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(data_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;66;03m# Phương sai thấp\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# 4 Cột phân loại (Cat): H có tần suất thống trị (>95%)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCat_F\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlue\u001b[39m\u001b[38;5;124m'\u001b[39m], data_size, p\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]),\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCat_G\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m], data_size, p\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]),\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCat_H\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m490\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCat_I\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m], data_size)\n\u001b[0;32m     29\u001b[0m })\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Thêm 40 cột giả lập khác để mô phỏng 49 cột\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m41\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. TẠO DỮ LIỆU GIẢ LẬP VÀ XÁC ĐỊNH CỘT (Thay thế bằng data thực của bạn)\n",
    "# ==============================================================================\n",
    "np.random.seed(42)\n",
    "data_size = 500\n",
    "df = pd.DataFrame({\n",
    "    # 5 Cột số (Num): A và D tương quan cao, E phương sai thấp\n",
    "    'Num_A': np.random.rand(data_size) * 10,\n",
    "    'Num_B': np.random.normal(50, 10, data_size),\n",
    "    'Num_C': (np.random.rand(data_size) * 0.9) + (np.random.rand(data_size) * 0.8), \n",
    "    'Num_D': (np.random.rand(data_size) * 0.1) + (df['Num_A'] * 0.95), # Tương quan rất cao với Num_A\n",
    "    'Num_E': np.random.rand(data_size) * 0.001 + 100, # Phương sai thấp\n",
    "\n",
    "    # 4 Cột phân loại (Cat): H có tần suất thống trị (>95%)\n",
    "    'Cat_F': np.random.choice(['Red', 'Green', 'Blue'], data_size, p=[0.7, 0.2, 0.1]),\n",
    "    'Cat_G': np.random.choice(['A', 'B', 'C', 'D'], data_size, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'Cat_H': ['High'] * 490 + ['Low'] * 10, \n",
    "    'Cat_I': np.random.choice(['X', 'Y', 'Z'], data_size)\n",
    "})\n",
    "# Thêm 40 cột giả lập khác để mô phỏng 49 cột\n",
    "for i in range(1, 41):\n",
    "    df[f'Other_Col_{i}'] = np.random.rand(data_size)\n",
    "\n",
    "# Loại bỏ các cột không phải số/chuỗi nếu có\n",
    "df = df.select_dtypes(include=['number', 'object'])\n",
    "print(f\"Tổng số cột ban đầu: {df.shape[1]}\")\n",
    "\n",
    "# Phân loại cột ban đầu\n",
    "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. EDA VÀ LỰA CHỌN BIẾN (FEATURE SELECTION) TRÊN TOÀN BỘ DỮ LIỆU GỐC\n",
    "# ==============================================================================\n",
    "\n",
    "# Khởi tạo tập hợp các cột cần loại bỏ\n",
    "cols_to_drop = set()\n",
    "\n",
    "# --- 2.1. Loại bỏ Missing Values (>50%) ---\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "cols_to_drop_missing = missing_percentage[missing_percentage > 50].index.tolist()\n",
    "cols_to_drop.update(cols_to_drop_missing)\n",
    "\n",
    "if cols_to_drop_missing:\n",
    "    print(f\"🚫 Loại bỏ {len(cols_to_drop_missing)} cột có >50% Missing Values.\")\n",
    "else:\n",
    "    print(\"✅ Không có cột nào bị loại bỏ do Missing Values quá cao.\")\n",
    "\n",
    "# Cập nhật danh sách cột sau khi loại bỏ Missing\n",
    "num_cols = [col for col in num_cols if col not in cols_to_drop]\n",
    "cat_cols = [col for col in cat_cols if col not in cols_to_drop]\n",
    "\n",
    "# --- 2.2. Lựa chọn Biến Số (Numerical Feature Selection) ---\n",
    "STD_THRESHOLD = 0.01 \n",
    "CORR_THRESHOLD = 0.9 \n",
    "\n",
    "# Phương sai Thấp\n",
    "low_variance_cols = [col for col in num_cols if df[col].std() < STD_THRESHOLD]\n",
    "cols_to_drop.update(low_variance_cols)\n",
    "if low_variance_cols:\n",
    "    print(f\"\\n🚫 Loại bỏ do Phương sai Thấp (STD < {STD_THRESHOLD}): {low_variance_cols}\")\n",
    "\n",
    "# Tương quan Cao\n",
    "num_cols_after_var = [col for col in num_cols if col not in cols_to_drop]\n",
    "corr_matrix = df[num_cols_after_var].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "for column in upper.columns:\n",
    "    correlated_cols = upper.index[upper[column] > CORR_THRESHOLD].tolist()\n",
    "    for row in correlated_cols:\n",
    "        if column not in cols_to_drop:\n",
    "            cols_to_drop.add(column) \n",
    "            print(f\"   - Tương quan cao ({upper.loc[row, column]:.2f}): Giữ '{row}', Loại bỏ '{column}'\")\n",
    "\n",
    "# --- 2.3. Lựa chọn Biến Phân loại (Categorical Feature Selection) ---\n",
    "FREQ_THRESHOLD = 0.95 \n",
    "\n",
    "# Tần suất Thống trị\n",
    "cat_to_drop_freq = [col for col in cat_cols if df[col].value_counts(normalize=True).iloc[0] > FREQ_THRESHOLD]\n",
    "cols_to_drop.update(cat_to_drop_freq)\n",
    "if cat_to_drop_freq:\n",
    "    print(f\"\\n🚫 Loại bỏ cột Cat do Tần suất Thống trị (>95%): {cat_to_drop_freq}\")\n",
    "\n",
    "# Tương quan Cramer's V (đơn giản hóa vì hiếm khi dùng cho lượng lớn cột)\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(r - 1, k - 1))\n",
    "\n",
    "# (Bỏ qua việc tính Cramer's V lặp vì quá tốn kém trên code mẫu 49 cột)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. KẾT QUẢ FEATURE SELECTION VÀ CHIA TRAIN-TEST SPLIT\n",
    "# ==============================================================================\n",
    "final_selected_cols = [col for col in df.columns if col not in cols_to_drop]\n",
    "final_num_cols = [col for col in num_cols if col not in cols_to_drop]\n",
    "final_cat_cols = [col for col in cat_cols if col not in cols_to_drop]\n",
    "\n",
    "# Áp dụng Feature Selection\n",
    "df_clean = df[final_selected_cols]\n",
    "\n",
    "# CHIA TRAIN/TEST\n",
    "df_train, df_test = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"TỔNG KẾT FS: Đã giảm từ {df.shape[1]} cột xuống còn {len(final_selected_cols)} cột.\")\n",
    "print(f\"Kích thước tập Train đã làm sạch: {df_train.shape}\")\n",
    "print(f\"Cột Số cuối cùng ({len(final_num_cols)}): {final_num_cols[:5]}...\")\n",
    "print(f\"Cột Cat cuối cùng ({len(final_cat_cols)}): {final_cat_cols}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. TIỀN XỬ LÝ (PREPROCESSING) SAU KHI CHIA (Áp dụng cho Học Không Giám Sát)\n",
    "# ==============================================================================\n",
    "\n",
    "# Chúng ta chỉ FIT trên tập TRAIN để tránh Data Leakage\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Scaling cho cột số (Quan trọng cho K-Means, PCA)\n",
    "        ('num', StandardScaler(), final_num_cols),\n",
    "        # Encoding cho cột phân loại\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), final_cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough' # Giữ lại các cột khác (nếu có)\n",
    ")\n",
    "\n",
    "# Xây dựng Pipeline (Dù không có mô hình, vẫn dùng Pipeline để áp dụng Preprocessing)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# FIT và TRANSFORM trên TRAIN\n",
    "df_train_processed = pipeline.fit_transform(df_train)\n",
    "\n",
    "# CHỈ TRANSFORM trên TEST\n",
    "df_test_processed = pipeline.transform(df_test)\n",
    "\n",
    "# Chuyển về DataFrame để dễ nhìn hơn\n",
    "feature_names = final_num_cols + list(pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(final_cat_cols))\n",
    "df_train_final = pd.DataFrame(df_train_processed, columns=feature_names)\n",
    "df_test_final = pd.DataFrame(df_test_processed, columns=feature_names)\n",
    "\n",
    "print(f\"Kích thước tập Train SAU PREPROCESSING: {df_train_final.shape} (Số cột đã tăng do One-Hot Encoding)\")\n",
    "print(\"Dữ liệu đã sẵn sàng cho các thuật toán Unsupervised Learning (K-Means, PCA, v.v.).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232afc2",
   "metadata": {},
   "source": [
    "# Supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb74dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "\n",
    "# ==============================================================================\n",
    "# 1. NẠP DỮ LIỆU VÀ CHIA TRAIN-TEST SPLIT (Feature Selection được bỏ qua cho ngắn gọn)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- TẠO DỮ LIỆU GIẢ LẬP VÀ BIẾN MỤC TIÊU ---\n",
    "np.random.seed(42)\n",
    "data_size = 500\n",
    "df = pd.DataFrame({\n",
    "    'Num_A': np.random.rand(data_size) * 10,\n",
    "    'Num_B': np.random.normal(50, 10, data_size),\n",
    "    'Cat_F': np.random.choice(['Red', 'Green', 'Blue'], data_size, p=[0.7, 0.2, 0.1]),\n",
    "    'Cat_G': np.random.choice(['A', 'B', 'C', 'D'], data_size, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'Target': np.where((np.random.rand(data_size) + np.random.rand(data_size)) > 1, 1, 0)\n",
    "})\n",
    "\n",
    "# Xác định cột\n",
    "TARGET_COL = 'Target'\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Chia Train/Test (sử dụng stratify)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Phân loại cột sau khi chia\n",
    "num_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"Kích thước X_train: {X_train.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TIỀN XỬ LÝ (PREPROCESSING) THỦ CÔNG (KHÔNG DÙNG PIPELINE)\n",
    "# ==============================================================================\n",
    "\n",
    "# Khởi tạo các bộ biến đổi\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# --- A. XỬ LÝ CỘT SỐ (SCALING) ---\n",
    "\n",
    "print(\"Bắt đầu xử lý cột số (Scaling)...\")\n",
    "\n",
    "# 1. FIT (chỉ trên X_train)\n",
    "scaler.fit(X_train[num_cols])\n",
    "\n",
    "# 2. TRANSFORM (trên X_train và X_test)\n",
    "X_train_scaled = scaler.transform(X_train[num_cols])\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Chuyển về DataFrame tạm thời (để dễ dàng ghép nối)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "\n",
    "# --- B. XỬ LÝ CỘT PHÂN LOẠI (ENCODING) ---\n",
    "\n",
    "print(\"Bắt đầu xử lý cột phân loại (One-Hot Encoding)...\")\n",
    "\n",
    "# 1. FIT (chỉ trên X_train)\n",
    "encoder.fit(X_train[cat_cols])\n",
    "\n",
    "# Lấy tên cột mới sau One-Hot Encoding\n",
    "encoded_cols = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "# 2. TRANSFORM (trên X_train và X_test)\n",
    "X_train_encoded = encoder.transform(X_train[cat_cols])\n",
    "X_test_encoded = encoder.transform(X_test[cat_cols])\n",
    "\n",
    "# Chuyển về DataFrame tạm thời\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_cols, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
    "\n",
    "\n",
    "# --- C. GHÉP NỐI (CONCATENATE) DỮ LIỆU ĐÃ XỬ LÝ ---\n",
    "\n",
    "# Loại bỏ các cột gốc đã được xử lý khỏi tập dữ liệu ban đầu\n",
    "X_train_removed = X_train.drop(columns=num_cols + cat_cols)\n",
    "X_test_removed = X_test.drop(columns=num_cols + cat_cols)\n",
    "\n",
    "# Ghép nối các tập dữ liệu đã xử lý\n",
    "X_train_final = pd.concat([X_train_scaled_df, X_train_encoded_df, X_train_removed], axis=1)\n",
    "X_test_final = pd.concat([X_test_scaled_df, X_test_encoded_df, X_test_removed], axis=1)\n",
    "\n",
    "print(f\"\\nKích thước X_train sau xử lý: {X_train_final.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. HUẤN LUYỆN VÀ ĐÁNH GIÁ MÔ HÌNH\n",
    "# ==============================================================================\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "\n",
    "# Huấn luyện mô hình trên tập TRAIN cuối cùng\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "# Dự đoán trên tập TEST cuối cùng\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "# Đánh giá\n",
    "print(\"--- ĐÁNH GIÁ MÔ HÌNH TRÊN TẬP TEST ---\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
